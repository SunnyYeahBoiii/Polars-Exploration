{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ee2f0b",
   "metadata": {},
   "source": [
    "## Data types\n",
    "Polars supports a variety of data types that fall broadly under the following categories:\n",
    "\n",
    "- Numeric data types: signed integers, unsigned integers, floating point numbers, and decimals.\n",
    "- Nested data types: lists, structs, and arrays.\n",
    "- Temporal: dates, datetimes, times, and time deltas.\n",
    "- Miscellaneous: strings, binary data, Booleans, categoricals, enums, and objects.\n",
    "All types support missing values represented by the special value null. This is not to be conflated with the special value NaN in floating number data types; see the [section about floating point numbers](https://docs.pola.rs/user-guide/concepts/data-types-and-structures/#floating-point-numbers) for more information.\n",
    "\n",
    "You can also find a [full table with all data types supported in the appendix](https://docs.pola.rs/user-guide/concepts/data-types-and-structures/#appendix-full-data-types-table) with notes on when to use each data type and with links to relevant parts of the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd79703",
   "metadata": {},
   "source": [
    "## Series\n",
    "The core base data structures provided by Polars are series and dataframes. A series is a 1-dimensional homogeneous data structure. By \u201chomogeneous\u201d we mean that all elements inside a series have the same data type. The snippet below shows how to create a named series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e184dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5,)\n",
      "Series: 'ints' [i64]\n",
      "[\n",
      "\t1\n",
      "\t2\n",
      "\t3\n",
      "\t4\n",
      "\t5\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "s = pl.Series(\"ints\", [1, 2, 3, 4, 5])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622560e4",
   "metadata": {},
   "source": [
    "When creating a series, Polars will infer the data type from the values you provide. You can specify a concrete data type to override the inference mechanism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f076230b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64 UInt64\n"
     ]
    }
   ],
   "source": [
    "s1 = pl.Series(\"ints\", [1, 2, 3, 4, 5])\n",
    "s2 = pl.Series(\"uints\", [1, 2, 3, 4, 5], dtype=pl.UInt64)\n",
    "print(s1.dtype, s2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d50e3f",
   "metadata": {},
   "source": [
    "## Dataframe\n",
    "\n",
    "A dataframe is a 2-dimensional heterogeneous data structure that contains uniquely named series. By holding your data in a dataframe you will be able to use the Polars API to write queries that manipulate your data. You will be able to do this by using the [contexts and expressions provided by Polars](https://docs.pola.rs/user-guide/concepts/expressions-and-contexts/) that we will talk about next.\n",
    "\n",
    "The snippet below shows how to create a dataframe from a dictionary of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78d5619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 4)\n",
      "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
      "\u2502 name           \u2506 birthdate  \u2506 weight \u2506 height \u2502\n",
      "\u2502 ---            \u2506 ---        \u2506 ---    \u2506 ---    \u2502\n",
      "\u2502 str            \u2506 date       \u2506 f64    \u2506 f64    \u2502\n",
      "\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n",
      "\u2502 Alice Archer   \u2506 1997-01-10 \u2506 57.9   \u2506 1.56   \u2502\n",
      "\u2502 Ben Brown      \u2506 1985-02-15 \u2506 72.5   \u2506 1.77   \u2502\n",
      "\u2502 Chloe Cooper   \u2506 1983-03-22 \u2506 53.6   \u2506 1.65   \u2502\n",
      "\u2502 Daniel Donovan \u2506 1981-04-30 \u2506 83.1   \u2506 1.75   \u2502\n",
      "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice Archer\", \"Ben Brown\", \"Chloe Cooper\", \"Daniel Donovan\"],\n",
    "        \"birthdate\": [\n",
    "            date(1997, 1, 10),\n",
    "            date(1985, 2, 15),\n",
    "            date(1983, 3, 22),\n",
    "            date(1981, 4, 30),\n",
    "        ],\n",
    "        \"weight\": [57.9, 72.5, 53.6, 83.1],  # (kg)\n",
    "        \"height\": [1.56, 1.77, 1.65, 1.75],  # (m)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f5c1a3",
   "metadata": {},
   "source": [
    "### Inspecting a dataframe\n",
    "In this subsection we will show some useful methods to quickly inspect a dataframe. We will use the dataframe we created earlier as a starting point.\n",
    "\n",
    "#### Head\n",
    "The function head shows the first rows of a dataframe. By default, you get the first 5 rows but you can also specify the number of rows you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c0defdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
      "\u2502 name         \u2506 birthdate  \u2506 weight \u2506 height \u2502\n",
      "\u2502 ---          \u2506 ---        \u2506 ---    \u2506 ---    \u2502\n",
      "\u2502 str          \u2506 date       \u2506 f64    \u2506 f64    \u2502\n",
      "\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n",
      "\u2502 Alice Archer \u2506 1997-01-10 \u2506 57.9   \u2506 1.56   \u2502\n",
      "\u2502 Ben Brown    \u2506 1985-02-15 \u2506 72.5   \u2506 1.77   \u2502\n",
      "\u2502 Chloe Cooper \u2506 1983-03-22 \u2506 53.6   \u2506 1.65   \u2502\n",
      "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
     ]
    }
   ],
   "source": [
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5076bb38",
   "metadata": {},
   "source": [
    "#### Glimpse\n",
    "The function glimpse is another function that shows the values of the first few rows of a dataframe, but formats the output differently from head. Here, each line of the output corresponds to a single column, making it easier to inspect wider dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2bc493d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 4\n",
      "Columns: 4\n",
      "$ name       <str> 'Alice Archer', 'Ben Brown', 'Chloe Cooper', 'Daniel Donovan'\n",
      "$ birthdate <date> 1997-01-10, 1985-02-15, 1983-03-22, 1981-04-30\n",
      "$ weight     <f64> 57.9, 72.5, 53.6, 83.1\n",
      "$ height     <f64> 1.56, 1.77, 1.65, 1.75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8800/3691193966.py:1: DeprecationWarning: the argument `return_as_string` for `DataFrame.glimpse` is deprecated. It was renamed to `return_type` in version 1.35.0.\n",
      "  print(df.glimpse(return_as_string=True))\n"
     ]
    }
   ],
   "source": [
    "print(df.glimpse(return_as_string=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a201deb7",
   "metadata": {},
   "source": [
    "#### Tail\n",
    "The function tail shows the last rows of a dataframe. By default, you get the last 5 rows but you can also specify the number of rows you want, similar to how head works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce850ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
      "\u2502 name           \u2506 birthdate  \u2506 weight \u2506 height \u2502\n",
      "\u2502 ---            \u2506 ---        \u2506 ---    \u2506 ---    \u2502\n",
      "\u2502 str            \u2506 date       \u2506 f64    \u2506 f64    \u2502\n",
      "\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n",
      "\u2502 Ben Brown      \u2506 1985-02-15 \u2506 72.5   \u2506 1.77   \u2502\n",
      "\u2502 Chloe Cooper   \u2506 1983-03-22 \u2506 53.6   \u2506 1.65   \u2502\n",
      "\u2502 Daniel Donovan \u2506 1981-04-30 \u2506 83.1   \u2506 1.75   \u2502\n",
      "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
     ]
    }
   ],
   "source": [
    "print(df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b165d64a",
   "metadata": {},
   "source": [
    "#### Sample\n",
    "\n",
    "If you think the first or last rows of your dataframe are not representative of your data, you can use sample to get an arbitrary number of randomly selected rows from the DataFrame. Note that the rows are not necessarily returned in the same order as they appear in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98aa2662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 4)\n",
      "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
      "\u2502 name         \u2506 birthdate  \u2506 weight \u2506 height \u2502\n",
      "\u2502 ---          \u2506 ---        \u2506 ---    \u2506 ---    \u2502\n",
      "\u2502 str          \u2506 date       \u2506 f64    \u2506 f64    \u2502\n",
      "\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n",
      "\u2502 Alice Archer \u2506 1997-01-10 \u2506 57.9   \u2506 1.56   \u2502\n",
      "\u2502 Ben Brown    \u2506 1985-02-15 \u2506 72.5   \u2506 1.77   \u2502\n",
      "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)  # For reproducibility.\n",
    "\n",
    "print(df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1853f68a",
   "metadata": {},
   "source": [
    "#### Describe\n",
    "\n",
    "You can also use describe to compute summary statistics for all columns of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "568bb513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9, 5)\n",
      "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
      "\u2502 statistic  \u2506 name           \u2506 birthdate           \u2506 weight    \u2506 height   \u2502\n",
      "\u2502 ---        \u2506 ---            \u2506 ---                 \u2506 ---       \u2506 ---      \u2502\n",
      "\u2502 str        \u2506 str            \u2506 str                 \u2506 f64       \u2506 f64      \u2502\n",
      "\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n",
      "\u2502 count      \u2506 4              \u2506 4                   \u2506 4.0       \u2506 4.0      \u2502\n",
      "\u2502 null_count \u2506 0              \u2506 0                   \u2506 0.0       \u2506 0.0      \u2502\n",
      "\u2502 mean       \u2506 null           \u2506 1986-09-04 00:00:00 \u2506 66.775    \u2506 1.6825   \u2502\n",
      "\u2502 std        \u2506 null           \u2506 null                \u2506 13.560082 \u2506 0.097082 \u2502\n",
      "\u2502 min        \u2506 Alice Archer   \u2506 1981-04-30          \u2506 53.6      \u2506 1.56     \u2502\n",
      "\u2502 25%        \u2506 null           \u2506 1983-03-22          \u2506 57.9      \u2506 1.65     \u2502\n",
      "\u2502 50%        \u2506 null           \u2506 1985-02-15          \u2506 72.5      \u2506 1.75     \u2502\n",
      "\u2502 75%        \u2506 null           \u2506 1985-02-15          \u2506 72.5      \u2506 1.75     \u2502\n",
      "\u2502 max        \u2506 Daniel Donovan \u2506 1997-01-10          \u2506 83.1      \u2506 1.77     \u2502\n",
      "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c74d60f",
   "metadata": {},
   "source": [
    "## Schema\n",
    "When talking about data (in a dataframe or otherwise) we can refer to its schema. The schema is a mapping of column or series names to the data types of those same columns or series.\n",
    "\n",
    "You can check the schema of a dataframe with schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a912cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema({'name': String, 'birthdate': Date, 'weight': Float64, 'height': Float64})\n"
     ]
    }
   ],
   "source": [
    "print(df.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db49a10",
   "metadata": {},
   "source": [
    "Much like with series, Polars will infer the schema of a dataframe when you create it but you can override the inference system if needed.\n",
    "\n",
    "In Python, you can specify an explicit schema by using a dictionary to map column names to data types. You can use the value None if you do not wish to override inference for a given column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "338abc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n",
      "\u2502 name   \u2506 age \u2502\n",
      "\u2502 ---    \u2506 --- \u2502\n",
      "\u2502 str    \u2506 u8  \u2502\n",
      "\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n",
      "\u2502 Alice  \u2506 27  \u2502\n",
      "\u2502 Ben    \u2506 39  \u2502\n",
      "\u2502 Chloe  \u2506 41  \u2502\n",
      "\u2502 Daniel \u2506 43  \u2502\n",
      "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Ben\", \"Chloe\", \"Daniel\"],\n",
    "        \"age\": [27, 39, 41, 43],\n",
    "    },\n",
    "    schema={\"name\": None, \"age\": pl.UInt8},\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf78137",
   "metadata": {},
   "source": [
    "If you only need to override the inference of some columns, the parameter schema_overrides tends to be more convenient because it lets you omit columns for which you do not want to override the inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d48453a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n",
      "\u2502 name   \u2506 age \u2502\n",
      "\u2502 ---    \u2506 --- \u2502\n",
      "\u2502 str    \u2506 u8  \u2502\n",
      "\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n",
      "\u2502 Alice  \u2506 27  \u2502\n",
      "\u2502 Ben    \u2506 39  \u2502\n",
      "\u2502 Chloe  \u2506 41  \u2502\n",
      "\u2502 Daniel \u2506 43  \u2502\n",
      "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n"
     ]
    }
   ],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Alice\", \"Ben\", \"Chloe\", \"Daniel\"],\n",
    "        \"age\": [27, 39, 41, 43],\n",
    "    },\n",
    "    schema_overrides={\"age\": pl.UInt8},\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d251f",
   "metadata": {},
   "source": [
    "## Data types internals\n",
    "Polars utilizes the [Arrow Columnar Format](https://arrow.apache.org/docs/format/Columnar.html) for its data orientation. Following this specification allows Polars to transfer data to/from other tools that also use the Arrow specification with little to no overhead.\n",
    "\n",
    "Polars gets most of its performance from its query engine, the optimizations it performs on your query plans, and from the parallelization that it employs when running [your expressions](https://docs.pola.rs/user-guide/concepts/expressions-and-contexts/#expressions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e3a32b",
   "metadata": {},
   "source": [
    "## Floating point numbers\n",
    "Polars generally follows the IEEE 754 floating point standard for Float32 and Float64, with some exceptions:\n",
    "\n",
    "- Any NaN compares equal to any other NaN, and greater than any non-NaN value.\n",
    "- Operations do not guarantee any particular behavior on the sign of zero or NaN, nor on the payload of NaN values. This is not just limited to arithmetic operations, e.g. a sort or group by operation may canonicalize all zeroes to +0 and all NaNs to a positive NaN without payload for efficient equality checks.\n",
    "\n",
    "Polars always attempts to provide reasonably accurate results for floating point computations but does not provide guarantees on the error unless mentioned otherwise. Generally speaking 100% accurate results are infeasibly expensive to achieve (requiring much larger internal representations than 64-bit floats), and thus some error is always to be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b8de8",
   "metadata": {},
   "source": [
    "## Appendix: Full Data Types Table\n",
    "\n",
    "| Type(s) | Details |\n",
    "|---------|----------|\n",
    "| Boolean | Boolean type that is bit packed efficiently. |\n",
    "| Int8, Int16, Int32, Int64, Int128 | Varying-precision signed integer types. |\n",
    "| UInt8, UInt16, UInt32, UInt64, UInt128 | Varying-precision unsigned integer types. |\n",
    "| Float16, Float32, Float64 | Varying-precision signed floating point numbers. |\n",
    "| Decimal | Decimal 128-bit type with optional precision and non-negative scale. Use this if you need fine-grained control over the precision of your floats and the operations you make on them. See Python's `decimal.Decimal` for documentation on what a decimal data type is. |\n",
    "| String | Variable length UTF-8 encoded string data, typically human-readable. |\n",
    "| Binary | Stores arbitrary, varying length raw binary data. |\n",
    "| Date | Represents a calendar date. |\n",
    "| Time | Represents a time of day. |\n",
    "| Datetime | Represents a calendar date and time of day. |\n",
    "| Duration | Represents a time duration. |\n",
    "| Array | Arrays with a known, fixed shape per series; akin to numpy arrays. Learn more about how arrays and lists differ and how to work with both. |\n",
    "| List | Homogeneous 1D container with variable length. Learn more about how arrays and lists differ and how to work with both. |\n",
    "| Object | Wraps arbitrary Python objects. |\n",
    "| Categorical | Efficient encoding of string data where the categories are inferred at runtime. Learn more about how categoricals and enums differ and how to work with both. |\n",
    "| Enum | Efficient ordered encoding of a set of predetermined string categories. Learn more about how categoricals and enums differ and how to work with both. |\n",
    "| Struct | Composite product type that can store multiple fields. Learn more about the data type Struct in its dedicated documentation section. |\n",
    "| Null | Represents null values. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}